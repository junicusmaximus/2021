{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3578e5",
   "metadata": {},
   "source": [
    "# 자연어 처리 전처리 이해하기 ft.Torchtext "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6594b",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756c18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think\n",
    "that they can change the world, are the ones who do.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fe70e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here’s',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones,',\n",
       " 'the',\n",
       " 'misfits,',\n",
       " 'the',\n",
       " 'rebels,',\n",
       " 'the',\n",
       " 'troublemakers,',\n",
       " 'the',\n",
       " 'round',\n",
       " 'pegs',\n",
       " 'in',\n",
       " 'the',\n",
       " 'square',\n",
       " 'holes.',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'see',\n",
       " 'things',\n",
       " 'differently',\n",
       " '—',\n",
       " 'they’re',\n",
       " 'not',\n",
       " 'fond',\n",
       " 'of',\n",
       " 'rules.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'quote',\n",
       " 'them,',\n",
       " 'disagree',\n",
       " 'with',\n",
       " 'them,',\n",
       " 'glorify',\n",
       " 'or',\n",
       " 'vilify',\n",
       " 'them,',\n",
       " 'but',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'you',\n",
       " 'can’t',\n",
       " 'do',\n",
       " 'is',\n",
       " 'ignore',\n",
       " 'them',\n",
       " 'because',\n",
       " 'they',\n",
       " 'change',\n",
       " 'things.',\n",
       " 'They',\n",
       " 'push',\n",
       " 'the',\n",
       " 'human',\n",
       " 'race',\n",
       " 'forward,',\n",
       " 'and',\n",
       " 'while',\n",
       " 'some',\n",
       " 'may',\n",
       " 'see',\n",
       " 'them',\n",
       " 'as',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones,',\n",
       " 'we',\n",
       " 'see',\n",
       " 'genius,',\n",
       " 'because',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'are',\n",
       " 'crazy',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'think',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world,',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'do.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580f206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: regex in c:\\users\\jun-hyung lee\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from nltk) (4.61.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f51db9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jun-Hyung Lee\\\\Tuesday_seminar'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfd3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032c7c4",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ff9cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here',\n",
       " '’',\n",
       " 's',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones',\n",
       " ',',\n",
       " 'the',\n",
       " 'misfits',\n",
       " ',',\n",
       " 'the',\n",
       " 'rebels',\n",
       " ',',\n",
       " 'the',\n",
       " 'troublemakers',\n",
       " ',',\n",
       " 'the',\n",
       " 'round',\n",
       " 'pegs',\n",
       " 'in',\n",
       " 'the',\n",
       " 'square',\n",
       " 'holes',\n",
       " '.',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'see',\n",
       " 'things',\n",
       " 'differently',\n",
       " '—',\n",
       " 'they',\n",
       " '’',\n",
       " 're',\n",
       " 'not',\n",
       " 'fond',\n",
       " 'of',\n",
       " 'rules',\n",
       " '.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'quote',\n",
       " 'them',\n",
       " ',',\n",
       " 'disagree',\n",
       " 'with',\n",
       " 'them',\n",
       " ',',\n",
       " 'glorify',\n",
       " 'or',\n",
       " 'vilify',\n",
       " 'them',\n",
       " ',',\n",
       " 'but',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'you',\n",
       " 'can',\n",
       " '’',\n",
       " 't',\n",
       " 'do',\n",
       " 'is',\n",
       " 'ignore',\n",
       " 'them',\n",
       " 'because',\n",
       " 'they',\n",
       " 'change',\n",
       " 'things',\n",
       " '.',\n",
       " 'They',\n",
       " 'push',\n",
       " 'the',\n",
       " 'human',\n",
       " 'race',\n",
       " 'forward',\n",
       " ',',\n",
       " 'and',\n",
       " 'while',\n",
       " 'some',\n",
       " 'may',\n",
       " 'see',\n",
       " 'them',\n",
       " 'as',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones',\n",
       " ',',\n",
       " 'we',\n",
       " 'see',\n",
       " 'genius',\n",
       " ',',\n",
       " 'because',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'are',\n",
       " 'crazy',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'think',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'do',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c1d00",
   "metadata": {},
   "source": [
    "- large corpus일 경우에는 sklearn이 이전 것보다 더 활용적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c2bf0",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a4744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "texts = [\n",
    "\"\"\"Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think that they can change the world, are the ones who do.\"\"\" ,\n",
    " \n",
    "'I choose a lazy person to do a hard job. Because a lazy person will find an easy way to do it.'\n",
    "]\n",
    "df = pd.DataFrame({'author': ['jobs', 'gates'], 'text':texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b740f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jobs</td>\n",
       "      <td>Here’s to the crazy ones, the misfits, the reb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gates</td>\n",
       "      <td>I choose a lazy person to do a hard job. Becau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               text\n",
       "0   jobs  Here’s to the crazy ones, the misfits, the reb...\n",
       "1  gates  I choose a lazy person to do a hard job. Becau..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0183c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# initialize\n",
    "cv = CountVectorizer(stop_words='english') \n",
    "cv_matrix = cv.fit_transform(df['text']) \n",
    "# create document term matrix\n",
    "df_dtm = pd.DataFrame(cv_matrix.toarray(), index=df['author'].values, columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb455e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change</th>\n",
       "      <th>choose</th>\n",
       "      <th>crazy</th>\n",
       "      <th>differently</th>\n",
       "      <th>disagree</th>\n",
       "      <th>easy</th>\n",
       "      <th>fond</th>\n",
       "      <th>forward</th>\n",
       "      <th>genius</th>\n",
       "      <th>glorify</th>\n",
       "      <th>...</th>\n",
       "      <th>round</th>\n",
       "      <th>rules</th>\n",
       "      <th>square</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>think</th>\n",
       "      <th>troublemakers</th>\n",
       "      <th>vilify</th>\n",
       "      <th>way</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jobs</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gates</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       change  choose  crazy  differently  disagree  easy  fond  forward  \\\n",
       "jobs        2       0      3            1         1     0     1        1   \n",
       "gates       0       1      0            0         0     1     0        0   \n",
       "\n",
       "       genius  glorify  ...  round  rules  square  thing  things  think  \\\n",
       "jobs        1        1  ...      1      1       1      1       2      1   \n",
       "gates       0        0  ...      0      0       0      0       0      0   \n",
       "\n",
       "       troublemakers  vilify  way  world  \n",
       "jobs               1       1    0      1  \n",
       "gates              0       0    1      0  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be53c0",
   "metadata": {},
   "source": [
    "- userful when the dataframe contains a large corpus - used as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4359c",
   "metadata": {},
   "source": [
    "# spaCy 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d27442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (8.0.7)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jun-hyung lee\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (4.61.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41ac8d",
   "metadata": {},
   "source": [
    "- language other than English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d9a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Por', 'los', 'locos', '.', 'Los', 'marginados', '.', 'Los', 'rebeldes', '.', 'Los', 'problematicos', '.', '\\n', 'Los', 'inadaptados', '.', 'Los', 'que', 'ven', 'las', 'cosas', 'de', 'una', 'manera', 'distinta', '.', 'A', 'los', 'que', 'no', 'les', 'gustan', '\\n', 'las', 'reglas', '.', 'Y', 'a', 'los', 'que', 'no', 'respetan', 'el', '“', 'status', 'quo', '”', '.', 'Puedes', 'citarlos', ',', 'discrepar', 'de', 'ellos', ',', '\\n', 'ensalzarlos', 'o', 'vilipendiarlos', '.', 'Pero', 'lo', 'que', 'no', 'puedes', 'hacer', 'es', 'ignorarlos', '…', 'Porque', 'ellos', '\\n', 'cambian', 'las', 'cosas', ',', 'empujan', 'hacia', 'adelante', 'la', 'raza', 'humana', 'y', ',', 'aunque', 'algunos', 'puedan', '\\n', 'considerarlos', 'locos', ',', 'nosotros', 'vemos', 'en', 'ellos', 'a', 'genios', '.', 'Porque', 'las', 'personas', 'que', 'están', '\\n', 'lo', 'bastante', 'locas', 'como', 'para', 'creer', 'que', 'pueden', 'cambiar', 'el', 'mundo', ',', 'son', 'las', 'que', 'lo', 'logran', '.']\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.es import Spanish\n",
    "nlp = Spanish()\n",
    "\n",
    "text_spanish = \"\"\"Por los locos. Los marginados. Los rebeldes. Los problematicos. \n",
    "Los inadaptados. Los que ven las cosas de una manera distinta. A los que no les gustan\n",
    "las reglas. Y a los que no respetan el “status quo”. Puedes citarlos, discrepar de ellos,\n",
    "ensalzarlos o vilipendiarlos. Pero lo que no puedes hacer es ignorarlos… Porque ellos\n",
    "cambian las cosas, empujan hacia adelante la raza humana y, aunque algunos puedan\n",
    "considerarlos locos, nosotros vemos en ellos a genios. Porque las personas que están\n",
    "lo bastante locas como para creer que pueden cambiar el mundo, son las que lo logran.\"\"\"\n",
    "\n",
    "doc = nlp(text_spanish)\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a7a30d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['But', 'soon', 'after', 'the', 'PATRIOT', 'Act', 'passed', ',', 'a', 'few', 'years', 'before', 'I', 'even', 'arrived', 'here', 'in', 'the', 'Senate', ',', 'I', 'began', 'hearing', 'concerns', 'from', 'people', 'of', 'every', 'background', 'and', 'political', 'leaning', 'that', 'this', 'law', ',', 'the', 'very', 'purpose', 'of', 'which', 'was', 'to', 'protect', 'us', ',', 'was', 'also', 'threatening', 'to', 'violate', 'some', 'of', 'the', 'rights', 'and', 'freedoms', 'that', 'we', 'hold', 'most', 'dear', ';', 'that', 'it', 'did', \"n't\", 'just', 'provide', 'law', 'enforcement', 'the', 'powers', 'it', 'needed', 'to', 'keep', 'us', 'safe', 'but', 'powers', 'that', 'it', 'did', \"n't\", 'need', 'to', 'invade', 'our', 'privacy', 'without', 'cause', 'or', 'suspicion', '.']\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "text_english = \"\"\"But soon after the PATRIOT Act passed, a few years before I even arrived here in the Senate, I began hearing concerns from people of every background and political leaning that this law, the very purpose of which was to protect us, was also threatening to violate some of the rights and freedoms that we hold most dear; that it didn't just provide law enforcement the powers it needed to keep us safe but powers that it didn't need to invade our privacy without cause or suspicion.\"\"\"\n",
    "\n",
    "doc = nlp(text_english)\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0af755",
   "metadata": {},
   "source": [
    "# spaCy 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bda13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text = \"A Dog Run back corner near spare bedrooms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd2ab72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-81d2f95e2abc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspacy_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspacy_en\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \"\"\"\n\u001b[1;32m---> 50\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize(en_text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(en_text)]\n",
    "\n",
    "print(tokenize(en_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2e4d9",
   "metadata": {},
   "source": [
    "# Genism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fd30b",
   "metadata": {},
   "source": [
    "- unsupervised topic modeling\n",
    "- natural language processing\n",
    "- also contains a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de37921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from gensim) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from gensim) (0.29.21)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jun-hyung lee\\anaconda3\\lib\\site-packages (from gensim) (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df800b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jun-Hyung Lee\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Here',\n",
       " 's',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones',\n",
       " 'the',\n",
       " 'misfits',\n",
       " 'the',\n",
       " 'rebels',\n",
       " 'the',\n",
       " 'troublemakers',\n",
       " 'the',\n",
       " 'round',\n",
       " 'pegs',\n",
       " 'in',\n",
       " 'the',\n",
       " 'square',\n",
       " 'holes',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'see',\n",
       " 'things',\n",
       " 'differently',\n",
       " 'they',\n",
       " 're',\n",
       " 'not',\n",
       " 'fond',\n",
       " 'of',\n",
       " 'rules',\n",
       " 'You',\n",
       " 'can',\n",
       " 'quote',\n",
       " 'them',\n",
       " 'disagree',\n",
       " 'with',\n",
       " 'them',\n",
       " 'glorify',\n",
       " 'or',\n",
       " 'vilify',\n",
       " 'them',\n",
       " 'but',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'you',\n",
       " 'can',\n",
       " 't',\n",
       " 'do',\n",
       " 'is',\n",
       " 'ignore',\n",
       " 'them',\n",
       " 'because',\n",
       " 'they',\n",
       " 'change',\n",
       " 'things',\n",
       " 'They',\n",
       " 'push',\n",
       " 'the',\n",
       " 'human',\n",
       " 'race',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'while',\n",
       " 'some',\n",
       " 'may',\n",
       " 'see',\n",
       " 'them',\n",
       " 'as',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones',\n",
       " 'we',\n",
       " 'see',\n",
       " 'genius',\n",
       " 'because',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'are',\n",
       " 'crazy',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'think',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'do']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "list(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1eb537",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567dcbcd",
   "metadata": {},
   "source": [
    "- split() - apostrophe ('') and comma(,) are not considered as tokens\n",
    "- word_tokenize - considered as tokens\n",
    "- sklearn - \n",
    "- spaCy - considers punctuation symbols as a separate token(even the new lines \\n were included)\n",
    "- Genism - splits every time it encounters a punctation symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77844364",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text = \"A Dog Run back corner near spare bedrooms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0ebfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(en_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacf986",
   "metadata": {},
   "source": [
    "한국어는 조사,접사등으로 단순 띄어쓰기 단위로 나누면 같은 단어가 다른 단어로 인식되어서 단어 집합의\n",
    "크기가 불필요하게 커짐\n",
    "*단어 집합  중복을 제거한 텍스트의 총 단어의 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246c9b5",
   "metadata": {},
   "source": [
    "'사과가', '사과를', '사과의', '사과와', '사과는'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a6916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_text = \"사과의 놀라운 효능이라는 글을 봤어. 그래서 오늘 사과를 먹으려고 했는데 사과가 썩어서 슈퍼에 가서 사과랑 오렌지 사왔어\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a19038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사과의', '놀라운', '효능이라는', '글을', '봤어.', '그래서', '오늘', '사과를', '먹으려고', '했는데', '사과가', '썩어서', '슈퍼에', '가서', '사과랑', '오렌지', '사왔어']\n"
     ]
    }
   ],
   "source": [
    "print(kor_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91821215",
   "metadata": {},
   "source": [
    "'의','가','를' 제거해주지 않아 기계는 전부 다른 단어로 인식 -> 따라서 형태소 분석기 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea914a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
